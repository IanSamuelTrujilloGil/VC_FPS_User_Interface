{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04f80c0a",
   "metadata": {},
   "source": [
    "## Módulo de inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602270bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import platform\n",
    "import subprocess\n",
    "import abc\n",
    "from enum import Enum, auto\n",
    "from pynput.keyboard import Controller as KBController, Key\n",
    "\n",
    "# TECLADO (MOVIMIENTO)\n",
    "\n",
    "kb = KBController()\n",
    "\n",
    "KEY_FORWARD = \"w\"\n",
    "KEY_LEFT = \"a\"\n",
    "KEY_RIGHT = \"d\"\n",
    "KEY_JUMP = Key.space\n",
    "\n",
    "class MoveHold(Enum):\n",
    "    NEUTRAL = auto()\n",
    "    FORWARD = auto()\n",
    "    LEFT = auto()\n",
    "    RIGHT = auto()\n",
    "\n",
    "def _release_keys(keys):\n",
    "    for k in keys:\n",
    "        try:\n",
    "            kb.release(k)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "def _tap(k, press_time=0.03):\n",
    "    try:\n",
    "        kb.press(k)\n",
    "        time.sleep(press_time)\n",
    "    finally:\n",
    "        try:\n",
    "            kb.release(k)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "class KeyboardMoveManager:\n",
    "    \"\"\"Mantiene 1 tecla de movimiento pulsada (W/A/D). Jump es tap independiente.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.current = MoveHold.NEUTRAL\n",
    "\n",
    "    def set_hold(self, hold: MoveHold):\n",
    "        if hold == self.current:\n",
    "            return\n",
    "\n",
    "        _release_keys([KEY_FORWARD, KEY_LEFT, KEY_RIGHT])\n",
    "\n",
    "        if hold == MoveHold.FORWARD:\n",
    "            kb.press(KEY_FORWARD)\n",
    "        elif hold == MoveHold.LEFT:\n",
    "            kb.press(KEY_LEFT)\n",
    "        elif hold == MoveHold.RIGHT:\n",
    "            kb.press(KEY_RIGHT)\n",
    "\n",
    "        self.current = hold\n",
    "\n",
    "    def jump(self):\n",
    "        _tap(KEY_JUMP, press_time=0.03)\n",
    "\n",
    "    def release_all(self):\n",
    "        _release_keys([KEY_FORWARD, KEY_LEFT, KEY_RIGHT])\n",
    "        self.current = MoveHold.NEUTRAL\n",
    "\n",
    "\n",
    "\n",
    "# RATÓN (FACTORY)\n",
    "class MouseInput(abc.ABC):\n",
    "    \"\"\"Clase envoltorio para enviar los inputs del ratón al juego\"\"\"\n",
    "    @abc.abstractmethod\n",
    "    def move(self, dx, dy): pass # Método para enviar movimientos del ratón\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def left_click(self): pass # Método para enviar evento de clic izquierdo\n",
    "\n",
    "\n",
    "class LinuxMouseInput(MouseInput):\n",
    "    \"\"\"Implementación en Linux. Requiere instalar la libreria 'xdotools'.\"\"\"\n",
    "    def move(self, dx, dy):\n",
    "        if dx == 0 and dy == 0:\n",
    "            return\n",
    "        try:\n",
    "            subprocess.Popen(\n",
    "                [\"xdotool\", \"mousemove_relative\", \"--\", str(int(dx)), str(int(dy))],\n",
    "                stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL\n",
    "            )\n",
    "        except FileNotFoundError:\n",
    "            print(\"Error: xdotool no instalado\")\n",
    "\n",
    "    def left_click(self):\n",
    "        try:\n",
    "            subprocess.Popen(\n",
    "                [\"xdotool\", \"click\", \"1\"],\n",
    "                stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL\n",
    "            )\n",
    "        except FileNotFoundError:\n",
    "            print(\"Error: xdotool no instalado\")\n",
    "\n",
    "\n",
    "class WindowsMouseInput(MouseInput):\n",
    "    \"\"\"Implementación en Windows. Requiere del uso de  'pydirectinput'. Desarrollada por si algún compañero usa Windows\"\"\"\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            import pydirectinput\n",
    "            self.engine = pydirectinput\n",
    "            self.engine.FAILSAFE = False\n",
    "            self.available = True\n",
    "        except ImportError:\n",
    "            print(\"Error: pydirectinput no instalado (pip install pydirectinput)\")\n",
    "            self.available = False\n",
    "\n",
    "    def move(self, dx, dy):\n",
    "        if not self.available or (dx == 0 and dy == 0):\n",
    "            return\n",
    "        self.engine.moveRel(int(dx), int(dy), relative=True)\n",
    "\n",
    "    def left_click(self):\n",
    "        if not self.available:\n",
    "            return\n",
    "        self.engine.click()\n",
    "\n",
    "\n",
    "class MouseInputFactory:\n",
    "    \"\"\"Factory para crear una instnacia de MouseInput de manera sencilla y sin tener que realizar comprobaciones\"\"\"\n",
    "    @staticmethod\n",
    "    def create():\n",
    "        system = platform.system()\n",
    "        if system == \"Linux\":\n",
    "            print(\"Sistema Linux detectado: Usando xdotool\")\n",
    "            return LinuxMouseInput()\n",
    "        elif system == \"Windows\":\n",
    "            print(\"Sistema Windows detectado: Usando pydirectinput\")\n",
    "            return WindowsMouseInput()\n",
    "        else:\n",
    "            print(f\"Sistema {system} no soportado oficialmente\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57da99b2",
   "metadata": {},
   "source": [
    "## Módulo de detección de gestos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f22c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import os\n",
    "import urllib.request\n",
    "from collections import deque\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "\n",
    "# CONTROLADOR DE POSE (MEDIAPIPE)\n",
    "# - Usa MediaPipe para detectar landmarks del cuerpo.\n",
    "# - Hace una calibración (neutral).\n",
    "# - En ejecución decide: izquierda/derecha, avanzar (forward) y salto (jump).\n",
    "\n",
    "LS, RS = 11, 12\n",
    "LH, RH = 23, 24\n",
    "MIN_VIS = 0.60\n",
    "\n",
    "# Tiempos de calibración (espera inicial, neutral, forward)\n",
    "PRE_CALIB_WAIT_SECONDS = 5.0\n",
    "CALIB_NEUTRAL_SECONDS = 2.0\n",
    "CALIB_FORWARD_SECONDS = 1.2\n",
    "\n",
    "# Umbrales y filtros para detectar inclinación lateral y forward (con histéresis y suavizado)\n",
    "LEAN_X_THRESH = 0.25\n",
    "EMA_DY = 0.35\n",
    "DY_ENTER_MIN = 0.030\n",
    "DY_STD_MULT = 6.0\n",
    "DY_FWD_FRAC = 0.70\n",
    "DY_EXIT_RATIO = 0.65\n",
    "STABLE_FRAMES_FWD = 3\n",
    "DY_UP_BLOCK_MIN = 0.020\n",
    "\n",
    "# Umbrales y filtros para detectar salto (altura + “velocidad”) y evitar dobles disparos\n",
    "EMA_Y = 0.30\n",
    "JUMP_UP_HIP = 0.10\n",
    "JUMP_VEL = 0.06\n",
    "JUMP_COOLDOWN_SEC = 0.55\n",
    "JUMP_PREBLOCK_UP = 0.06\n",
    "JUMP_PREBLOCK_VEL = 0.03\n",
    "STABLE_FRAMES_SIDE = 2\n",
    "\n",
    "# Conexiones entre landmarks para dibujar el esqueleto en pantalla (debug/visualización)\n",
    "POSE_CONNECTIONS = [\n",
    "    (11, 12), (11, 23), (12, 24), (23, 24),\n",
    "    (11, 13), (13, 15), (12, 14), (14, 16),\n",
    "    (23, 25), (25, 27), (24, 26), (26, 28),\n",
    "    (27, 31), (28, 32), (27, 29), (28, 30),\n",
    "    (29, 31), (30, 32)\n",
    "]\n",
    "\n",
    "def _vis(lm):\n",
    "    \"\"\"Lee la visibilidad del landmark (si no existe, asume 1.0)\"\"\"\n",
    "    return float(getattr(lm, \"visibility\", 1.0))\n",
    "\n",
    "def draw_pose(frame_bgr, lms):\n",
    "    \"\"\" Dibuja puntos y líneas de la pose sobre el frame (útil para ver qué está detectando)\"\"\"\n",
    "    h, w = frame_bgr.shape[:2]\n",
    "    for lm in lms:\n",
    "        cv2.circle(frame_bgr, (int(lm.x*w), int(lm.y*h)), 3, (255,255,255), -1)\n",
    "    for a, b in POSE_CONNECTIONS:\n",
    "        ax, ay = int(lms[a].x*w), int(lms[a].y*h)\n",
    "        bx, by = int(lms[b].x*w), int(lms[b].y*h)\n",
    "        cv2.line(frame_bgr, (ax, ay), (bx, by), (255,255,255), 2)\n",
    "\n",
    "def center_norm(lms, a, b):\n",
    "    \"\"\" Punto medio entre dos landmarks (sirve para centros de hombros y caderas)\"\"\"\n",
    "    return (\n",
    "        (lms[a].x + lms[b].x) * 0.5,\n",
    "        (lms[a].y + lms[b].y) * 0.5,\n",
    "        (lms[a].z + lms[b].z) * 0.5\n",
    "    )\n",
    "\n",
    "def extract_features(lms_norm):\n",
    "    \"\"\"Extrae las señales mínimas para controlar:\n",
    "     - lean_x: inclinación lateral normalizada (izq/der)\n",
    "     - shy: altura del centro de hombros (para forward)\n",
    "     - hip_y_norm: altura de cadera normalizada (para salto)\"\"\"\n",
    "    if not all(_vis(lms_norm[i]) >= MIN_VIS for i in (LS, RS, LH, RH)):\n",
    "        return None\n",
    "\n",
    "    shx, shy, _ = center_norm(lms_norm, LS, RS)\n",
    "    hix, hiy, _ = center_norm(lms_norm, LH, RH)\n",
    "\n",
    "    shoulder_w = abs(lms_norm[LS].x - lms_norm[RS].x) + 1e-6\n",
    "    lean_x = (shx - hix) / shoulder_w\n",
    "\n",
    "    torso_len = abs(hiy - shy) + 1e-6\n",
    "    hip_y_norm = hiy / torso_len\n",
    "\n",
    "    return {\"lean_x\": lean_x, \"shy\": shy, \"hip_y_norm\": hip_y_norm}\n",
    "\n",
    "class Debouncer:\n",
    "    \"\"\" Antirrebote: evita que la acción cambie por ruido exigiendo N frames seguidos iguales\"\"\"\n",
    "    def __init__(self):\n",
    "        self.last = None\n",
    "        self.count = 0\n",
    "    def reset(self):\n",
    "        self.last = None\n",
    "        self.count = 0\n",
    "    def update(self, proposed, need):\n",
    "        if proposed == self.last:\n",
    "            self.count += 1\n",
    "        else:\n",
    "            self.last = proposed\n",
    "            self.count = 1\n",
    "        return self.count >= need\n",
    "\n",
    "class PoseMovementController:\n",
    "    \"\"\" Controlador principal:\n",
    "     - Descarga el modelo si hace falta\n",
    "     - Inicializa PoseLandmarker en modo VIDEO (requiere timestamp)\n",
    "     - Calibra neutral/forward\n",
    "     - En RUN decide movimientos a partir de las features\"\"\"\n",
    "    MODEL_URL = \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task\"\n",
    "    MODEL_PATH = \"pose_landmarker_lite.task\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._ensure_model()\n",
    "        self._init_landmarker()\n",
    "\n",
    "        # Base de reloj monótono para generar timestamps consistentes\n",
    "        self._clock0 = time.monotonic()\n",
    "        self._last_ts_ms = 0\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def _ensure_model(self):\n",
    "        \"\"\" Si no existe el archivo del modelo, lo descarga\"\"\"\n",
    "        if not os.path.exists(self.MODEL_PATH):\n",
    "            print(\"Descargando modelo PoseLandmarker...\")\n",
    "            urllib.request.urlretrieve(self.MODEL_URL, self.MODEL_PATH)\n",
    "            print(\"OK:\", self.MODEL_PATH)\n",
    "\n",
    "    def _init_landmarker(self):\n",
    "        \"\"\" Crea el detector de pose con umbrales de confianza y modo VIDEO\"\"\"\n",
    "        BaseOptions = mp.tasks.BaseOptions\n",
    "        PoseLandmarker = mp.tasks.vision.PoseLandmarker\n",
    "        PoseLandmarkerOptions = mp.tasks.vision.PoseLandmarkerOptions\n",
    "        RunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "        self._landmarker = PoseLandmarker.create_from_options(\n",
    "            PoseLandmarkerOptions(\n",
    "                base_options=BaseOptions(model_asset_path=self.MODEL_PATH),\n",
    "                running_mode=RunningMode.VIDEO,\n",
    "                num_poses=1,\n",
    "                min_pose_detection_confidence=0.5,\n",
    "                min_pose_presence_confidence=0.5,\n",
    "                min_tracking_confidence=0.5\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\" Reinicia el flujo de calibración y los estados internos (filtros, historial, debouncer)\"\"\"\n",
    "        self.stage = \"WAIT\"\n",
    "        self.wait_start = None\n",
    "        self.calib_start = None\n",
    "        self.neu_feats = []\n",
    "        self.fwd_feats = []\n",
    "        self.neutral = None\n",
    "\n",
    "        self.dy_s = 0.0\n",
    "        self.y_s = 0.0\n",
    "        self.y_hist = deque(maxlen=10)\n",
    "        self.last_jump_time = 0.0\n",
    "        self.deb = Debouncer()\n",
    "        self.current_hold = MoveHold.NEUTRAL  # viene de la CELDA 1\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\" Cierre seguro del landmarker\"\"\"\n",
    "        try:\n",
    "            self._landmarker.close()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    def _decide(self, feat):\n",
    "        \"\"\" Lógica de decisión:\n",
    "         1) Prioriza lateral (izq/der) si la inclinación supera el umbral.\n",
    "         2) Detecta salto con altura + velocidad + cooldown.\n",
    "         3) Detecta forward con umbral dinámico + histéresis y bloqueos para no mezclarlo con salto.\"\"\"\n",
    "        lean_dx = feat[\"lean_x\"] - self.neutral[\"lean0\"]\n",
    "        if abs(lean_dx) > LEAN_X_THRESH:\n",
    "            action = MoveHold.RIGHT if lean_dx > 0 else MoveHold.LEFT\n",
    "            return action, False, None\n",
    "\n",
    "        y_raw = feat[\"hip_y_norm\"] - self.neutral[\"hip_y0\"]\n",
    "        self.y_s = EMA_Y * y_raw + (1.0 - EMA_Y) * self.y_s\n",
    "        self.y_hist.append(y_raw)\n",
    "\n",
    "        vel = 0.0\n",
    "        if len(self.y_hist) >= 4:\n",
    "            vel = (self.y_hist[-4] - self.y_hist[-1])\n",
    "\n",
    "        up = -(self.y_s)\n",
    "        now = time.time()\n",
    "        can_jump = (now - self.last_jump_time) >= JUMP_COOLDOWN_SEC\n",
    "        do_jump = can_jump and (up > JUMP_UP_HIP) and (vel > JUMP_VEL)\n",
    "        preblock_jump = (up > JUMP_PREBLOCK_UP and vel > JUMP_PREBLOCK_VEL)\n",
    "\n",
    "        dy_raw = (feat[\"shy\"] - self.neutral[\"shy0\"])\n",
    "        self.dy_s = EMA_DY * dy_raw + (1.0 - EMA_DY) * self.dy_s\n",
    "\n",
    "        dy_enter = max(DY_ENTER_MIN, DY_STD_MULT * self.neutral[\"dy_std\"], DY_FWD_FRAC * self.neutral[\"dy_fwd_delta\"])\n",
    "        dy_exit = dy_enter * DY_EXIT_RATIO\n",
    "\n",
    "        if self.dy_s < -DY_UP_BLOCK_MIN:\n",
    "            fb = MoveHold.NEUTRAL\n",
    "        else:\n",
    "            if self.current_hold != MoveHold.FORWARD and (do_jump or preblock_jump):\n",
    "                fb = MoveHold.NEUTRAL\n",
    "            else:\n",
    "                if self.current_hold == MoveHold.FORWARD:\n",
    "                    fb = MoveHold.FORWARD if self.dy_s > dy_exit else MoveHold.NEUTRAL\n",
    "                else:\n",
    "                    fb = MoveHold.FORWARD if self.dy_s > dy_enter else MoveHold.NEUTRAL\n",
    "\n",
    "        return fb, do_jump, None\n",
    "\n",
    "    def process_frame(self, frame_bgr):\n",
    "        \"\"\" Procesamiento de frame:\n",
    "         - Convierte a RGB y crea mp.Image\n",
    "         - Genera timestamp monótono creciente (requisito del modo VIDEO)\n",
    "         - Detecta pose, dibuja y extrae features\n",
    "         - Si no está calibrado: avanza por etapas WAIT/NEUTRAL/FORWARD y calcula baseline\n",
    "         - Si está calibrado: decide acción con debouncer y gestiona cooldown de salto\"\"\"\n",
    "        rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb)\n",
    "\n",
    "        timestamp_ms = int((time.monotonic() - self._clock0) * 1000)\n",
    "        if timestamp_ms <= self._last_ts_ms:\n",
    "            timestamp_ms = self._last_ts_ms + 1\n",
    "        self._last_ts_ms = timestamp_ms\n",
    "\n",
    "        result = self._landmarker.detect_for_video(mp_image, timestamp_ms)\n",
    "        feat = None\n",
    "\n",
    "        if result.pose_landmarks:\n",
    "            lms = result.pose_landmarks[0]\n",
    "            draw_pose(frame_bgr, lms)\n",
    "            feat = extract_features(lms)\n",
    "\n",
    "        do_jump = False\n",
    "\n",
    "        if self.stage != \"DONE\":\n",
    "            self.current_hold = MoveHold.NEUTRAL\n",
    "\n",
    "            if self.stage == \"WAIT\":\n",
    "                if feat is None:\n",
    "                    self.wait_start = None\n",
    "                else:\n",
    "                    if self.wait_start is None:\n",
    "                        self.wait_start = time.time()\n",
    "                    if (time.time() - self.wait_start) >= PRE_CALIB_WAIT_SECONDS:\n",
    "                        self.stage = \"NEUTRAL\"\n",
    "                        self.calib_start = None\n",
    "                        self.neu_feats.clear()\n",
    "                        self.fwd_feats.clear()\n",
    "\n",
    "            elif self.stage in (\"NEUTRAL\", \"FORWARD\"):\n",
    "                if feat is None:\n",
    "                    pass\n",
    "                else:\n",
    "                    if self.calib_start is None:\n",
    "                        self.calib_start = time.time()\n",
    "                        if self.stage == \"NEUTRAL\":\n",
    "                            self.neu_feats.clear()\n",
    "                        else:\n",
    "                            self.fwd_feats.clear()\n",
    "\n",
    "                    elapsed = time.time() - self.calib_start\n",
    "\n",
    "                    if self.stage == \"NEUTRAL\":\n",
    "                        self.neu_feats.append(feat)\n",
    "                        if elapsed >= CALIB_NEUTRAL_SECONDS and len(self.neu_feats) >= 10:\n",
    "                            self.stage = \"FORWARD\"\n",
    "                            self.calib_start = None\n",
    "\n",
    "                    elif self.stage == \"FORWARD\":\n",
    "                        self.fwd_feats.append(feat)\n",
    "                        if elapsed >= CALIB_FORWARD_SECONDS and len(self.fwd_feats) >= 8:\n",
    "                            lean0 = sum(f[\"lean_x\"] for f in self.neu_feats) / len(self.neu_feats)\n",
    "                            shy0 = sum(f[\"shy\"] for f in self.neu_feats) / len(self.neu_feats)\n",
    "                            hip_y0 = sum(f[\"hip_y_norm\"] for f in self.neu_feats) / len(self.neu_feats)\n",
    "\n",
    "                            dys = [f[\"shy\"] for f in self.neu_feats]\n",
    "                            dy_std = math.sqrt(sum((x - shy0) ** 2 for x in dys) / len(dys))\n",
    "\n",
    "                            shy_fwd = sum(f[\"shy\"] for f in self.fwd_feats) / len(self.fwd_feats)\n",
    "                            dy_fwd_delta = max(0.0, shy_fwd - shy0)\n",
    "\n",
    "                            self.neutral = {\n",
    "                                \"lean0\": lean0,\n",
    "                                \"shy0\": shy0,\n",
    "                                \"dy_std\": dy_std,\n",
    "                                \"dy_fwd_delta\": dy_fwd_delta,\n",
    "                                \"hip_y0\": hip_y0\n",
    "                            }\n",
    "                            self.stage = \"DONE\"\n",
    "                            self.deb.reset()\n",
    "                            self.dy_s = 0.0\n",
    "                            self.y_s = 0.0\n",
    "                            self.y_hist.clear()\n",
    "                            self.current_hold = MoveHold.NEUTRAL\n",
    "\n",
    "        else:\n",
    "            if feat is None:\n",
    "                self.current_hold = MoveHold.NEUTRAL\n",
    "                do_jump = False\n",
    "                self.dy_s = 0.0\n",
    "                self.y_s = 0.0\n",
    "                self.y_hist.clear()\n",
    "                self.deb.reset()\n",
    "            else:\n",
    "                proposed_raw, do_jump, _ = self._decide(feat)\n",
    "\n",
    "                need = STABLE_FRAMES_FWD if proposed_raw == MoveHold.FORWARD else STABLE_FRAMES_SIDE\n",
    "                if self.deb.update(proposed_raw, need):\n",
    "                    self.current_hold = proposed_raw\n",
    "\n",
    "                if do_jump:\n",
    "                    self.last_jump_time = time.time()\n",
    "\n",
    "        return self.current_hold, do_jump, self.stage, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f095e299",
   "metadata": {},
   "source": [
    "## Módulo de seguimiento del objeto apuntador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbbc6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import platform\n",
    "import subprocess\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# pygetwindow (solo Windows)\n",
    "if platform.system() == \"Windows\":\n",
    "    try:\n",
    "        import pygetwindow as gw\n",
    "    except Exception:\n",
    "        gw = None\n",
    "else:\n",
    "    gw = None\n",
    "\n",
    "\n",
    "# SEGUIDOR DE LA PISTOLA\n",
    "# Tracker del sistema. Utilizar el principalmente el algoritmo CSRT con un filtro de Kalman.\n",
    "# Calibra al principio mediante 3 perfiles (9 clicks). Si se pierde el algoritmo CSRT busca con\n",
    "# los perfiles calibrados en un área creciente alrededor de la zona que predice el filtro de Kalman. \n",
    "# Si no lo encuentra pasado un cierto número de tiempo, busca en toda la imagen.\n",
    "class ObjectTracker:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Inicializa la cámara, las variables de estado y la conexión con el ratón.\n",
    "        Configura los umbrales de brillo para el disparo y la sensibilidad del movimiento.\n",
    "        \"\"\"\n",
    "        self.cs2_active = False # Indica si la ventana del CS2 está activa y en primer plano\n",
    "        self.camera_control_enabled = False\n",
    "        self.sensitivity = 0.5 # Sensibilidades eje X e Y\n",
    "        self.sensitivity_y = 0.5\n",
    "        self.COUNTER_STRIKE_WINDOW_NAME = \"Counter-Strike 2\"\n",
    "\n",
    "        self.mouse_input = MouseInputFactory.create()\n",
    "\n",
    "        self.shoot_detection_enabled = True\n",
    "        self.brightness_threshold = 25 # Umbral para detectar el disparo de la pistola usada en el proyecto\n",
    "        self.last_shoot_time = 0\n",
    "        self.shoot_cooldown = 0.1\n",
    "        self.reset_state()\n",
    "\n",
    "    def reset_state(self):\n",
    "        \"\"\"\n",
    "        Reinicia todos los contadores, listas de texturas y estados del tracker.\n",
    "        Se llama al iniciar o al pulsar 'R' para recalibrar desde cero.\n",
    "        \"\"\"\n",
    "        self.texture_maps = [] # Lista de recortes tomados de la pistola por la cámara\n",
    "        self.target_colors_hsv = [] # Lista de naranjas extraidos de la pistola por la cámara\n",
    "        self.all_clicks_history = [] # Historial de los clicks de las calibraciones\n",
    "        self.calibration_stage = 0 # Fase del tracker (0, 1, 2 y 3)\n",
    "        self.current_clicks_coords = [] # Lista de los clics actuales\n",
    "        self.roi = None # Roi del objeto trackeado\n",
    "        self.lost_frames = 0\n",
    "        self.max_lost_frames = 30\n",
    "        self.search_expansion = False # Indica si está en modo búsqueda expandida (va creciendo alrededor de la predicción del filtro de Kalman)\n",
    "        self.pending_click = None # Clic a procesar\n",
    "        self.tracker = None # Se encarga de tener la referencia a la instancia del algoritmo CSRT \n",
    "        self.show_roi = True\n",
    "        self.texture_match_threshold = 0.70 # Umbral para tener en cuenta con la semejanza de la textura\n",
    "        self.search_window = 100 # Tamaño ventana de búsqueda\n",
    "        if hasattr(self, \"ambient_brightness\"):\n",
    "            delattr(self, \"ambient_brightness\")\n",
    "\n",
    "    def get_active_window_title(self):\n",
    "        \"\"\"\n",
    "        Obtiene el título de la ventana que está en primer plano en el sistema operativo.\n",
    "        \"\"\"\n",
    "        system_name = platform.system()\n",
    "        try:\n",
    "            if system_name == \"Windows\" and gw is not None:\n",
    "                window = gw.getActiveWindow()\n",
    "                return window.title if window else \"\"\n",
    "            else:\n",
    "                result = subprocess.check_output(\n",
    "                    [\"xdotool\", \"getactivewindow\", \"getwindowname\"],\n",
    "                    stderr=subprocess.STDOUT\n",
    "                )\n",
    "                return result.decode(\"utf-8\").strip()\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "\n",
    "    def adjust_mouse_sensitivity(self, delta, min_val=0.0, max_val=5.0):\n",
    "        \"\"\"Cambia la sensibilidad del movimiento enviado al juego.\"\"\"\n",
    "        self.sensitivity = max(min_val, min(max_val, self.sensitivity + delta))\n",
    "        self.sensitivity_y = max(min_val, min(max_val, self.sensitivity_y + delta))\n",
    "\n",
    "    def camera_tracking_to_mouse_input(self, cx, cy, frame_shape):\n",
    "        \"\"\"\n",
    "        Calcula el desplazamiento necesario desde el centro de la pantalla hasta el objeto\n",
    "        y envía el input al juego con la sensibilidad configurada.\n",
    "        \"\"\"\n",
    "        if not self.camera_control_enabled or not self.cs2_active or not self.mouse_input:\n",
    "            return\n",
    "        h, w = frame_shape[:2]\n",
    "        move_x = int((cx - w // 2) * self.sensitivity)\n",
    "        move_y = int((cy - h // 2) * self.sensitivity_y)\n",
    "        self.mouse_input.move(move_x, move_y)\n",
    "\n",
    "    def detect_shoot(self, frame):\n",
    "        \"\"\"\n",
    "        Detecta cambios bruscos de brillo (fogonazos) en la zona de seguimiento (ROI)\n",
    "        para enviar el comando de disparo al juego.\n",
    "        - Convierte la ROI a escala de grises.\n",
    "        - Calcula la media aritmética (np.mean) que es muy rápida.\n",
    "        - Compara con el brillo ambiente.\n",
    "        - Si supera el umbral, dispara.\n",
    "        \"\"\"\n",
    "        if (not self.shoot_detection_enabled or\n",
    "            not self.camera_control_enabled or\n",
    "            not self.cs2_active or\n",
    "            self.roi is None):\n",
    "            return False\n",
    "\n",
    "        # Cooldown de disparo.\n",
    "        current_time = time.time()\n",
    "        if current_time - self.last_shoot_time < self.shoot_cooldown:\n",
    "            return False\n",
    "\n",
    "        x, y, w, h = [int(v) for v in self.roi] # Dimensiones de la roi como enteros\n",
    "        fh, fw = frame.shape[:2] # Alto y Ancho de la pantalla\n",
    "        x1, y1, x2, y2 = max(0, x), max(0, y), min(fw, x + w), min(fh, y + h)\n",
    "\n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            return False\n",
    "\n",
    "        roi_bgr = frame[y1:y2, x1:x2]\n",
    "        gray_roi = cv2.cvtColor(roi_bgr, cv2.COLOR_BGR2GRAY)\n",
    "        current_intensity = np.mean(gray_roi)\n",
    "\n",
    "        if not hasattr(self, \"ambient_brightness\"):\n",
    "            self.ambient_brightness = current_intensity\n",
    "\n",
    "        diff = current_intensity - self.ambient_brightness\n",
    "        if diff > self.brightness_threshold:\n",
    "            self.last_shoot_time = current_time\n",
    "            if self.mouse_input:\n",
    "                self.mouse_input.left_click()\n",
    "            return True\n",
    "        else:\n",
    "            self.ambient_brightness = self.ambient_brightness * 0.8 + current_intensity * 0.2 # Adaptación a la luz ambiente\n",
    "            return False\n",
    "\n",
    "    def mouse_callback(self, event, x, y, flags, param):\n",
    "        \"\"\"Captura los clics del usuario durante la fase de calibración.\"\"\"\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            self.pending_click = (x, y)\n",
    "\n",
    "    def process_pending_click(self, frame):\n",
    "        \"\"\"Procesa el clic guardado, almacenando la coordenada para definir el perfil del objeto.\"\"\"\n",
    "        if self.pending_click is None:\n",
    "            return\n",
    "        x, y = self.pending_click\n",
    "        self.pending_click = None\n",
    "\n",
    "        self.current_clicks_coords.append((x, y))\n",
    "        self.all_clicks_history.append((x, y))\n",
    "        print(f\"Click {len(self.current_clicks_coords)}/3 guardado.\")\n",
    "\n",
    "        if len(self.current_clicks_coords) >= 3:\n",
    "            self.finalize_stage(frame)\n",
    "\n",
    "    def finalize_stage(self, frame):\n",
    "        \"\"\"\n",
    "        Se ejecuta tras la calibración de 3 fases (9 clics).\n",
    "        - Calcula el círculo que encierra los puntos.\n",
    "        - Obtiene el cuadrado que tiene esa circunferencia circunscrita\n",
    "        - Recorta esa zona como 'Textura Maestra'.\n",
    "        - Calcula el color HSV promedio de esa zona.\n",
    "        - Guarda ambos datos y avanza a la siguiente fase de la calibración.\n",
    "        \"\"\"\n",
    "        points = np.array(self.current_clicks_coords, dtype=np.int32)\n",
    "        (cx, cy), radius = cv2.minEnclosingCircle(points) # Se queda con la circunferencia más pequeña capaz de obtener esos puntos\n",
    "\n",
    "        # Con la circunferencia obtiene el cuadrado que la tiene circunscrita\n",
    "        padding = 5\n",
    "        side = int(radius * 2) + padding\n",
    "        rx = int(cx - radius - padding/2)\n",
    "        ry = int(cy - radius - padding/2)\n",
    "        h_frame, w_frame = frame.shape[:2]\n",
    "\n",
    "        rx = max(0, rx)\n",
    "        ry = max(0, ry)\n",
    "        rw = min(side, w_frame - rx)\n",
    "        rh = min(side, h_frame - ry)\n",
    "\n",
    "        if rw > 0 and rh > 0: # Si el recorte existe\n",
    "            texture_map = frame[ry:ry+rh, rx:rx+rw].copy()\n",
    "            self.texture_maps.append(texture_map) # Se guarda una copia de la imagen en ese cuadrado\n",
    "            hsv_roi = cv2.cvtColor(texture_map, cv2.COLOR_BGR2HSV)\n",
    "            avg_hsv = np.mean(hsv_roi, axis=(0, 1))\n",
    "            self.target_colors_hsv.append(avg_hsv) # Se guarda la media del color en hsv en el roi\n",
    "            print(f\"Mapa de Texturas {self.calibration_stage + 1} generado.\")\n",
    "\n",
    "            self.current_clicks_coords = []\n",
    "            self.calibration_stage += 1\n",
    "\n",
    "            if self.calibration_stage == 3:\n",
    "                self.roi = (rx, ry, rw, rh)\n",
    "                self.initialize_tracker_auto(frame) # Se manda a inicializar el tracker\n",
    "\n",
    "    def initialize_tracker_auto(self, frame):\n",
    "        \"\"\"Inicializa el tracker CSRT y el filtro Kalman con la última ROI calculada.\"\"\"\n",
    "        if not hasattr(cv2, \"TrackerCSRT_create\"):\n",
    "            raise RuntimeError(\"Falta CSRT: instala opencv-contrib-python\")\n",
    "        x, y, w, h = self.roi\n",
    "        cx, cy = x + w//2, y + h//2\n",
    "        self.tracker = cv2.TrackerCSRT_create()\n",
    "        self.tracker.init(frame, self.roi)\n",
    "        self.init_kalman(cx, cy)\n",
    "        print(\"TRACKER INICIADO.\")\n",
    "\n",
    "    def detect_by_texture(self, frame, pred_x, pred_y, full_scan=False):\n",
    "        \"\"\"\n",
    "        Motor de búsqueda visual con estrategia de 'Tolerancia Cero' para eliminar falsos positivos.\n",
    "        Combina Template Matching (Forma) con un filtrado estricto de Color (HSV).\n",
    "\n",
    "        Estrategia de Filtrado:\n",
    "        - Zona de Búsqueda:\n",
    "           - Normal: Busca solo alrededor de la predicción de Kalman\n",
    "           - Pánico: Busca en toda la imagen si el objeto se ha perdido > 0.5s.\n",
    "\n",
    "        - Escalas:\n",
    "           - Prueba variaciones de tamaño para tolerar que el usuario se aleje/acerque.\n",
    "\n",
    "        - Vetos de Color:\n",
    "           - HUE: Margen estricto de 15 grados. Si no es el naranja exacto, se descarta (intentando evitar que siga otras cosas)\n",
    "           - SAT: Mínimo 60. Si el candidato es grisáceo o sombra, se descarta.\n",
    "\n",
    "        - Umbrales de Confianza:\n",
    "           - Modo Local: Exige > 0.70 de coincidencia.\n",
    "           - Modo Pánico: Exige > 0.80 para intentar evitar reenganchar con otras cosas en la imagen.\n",
    "        \"\"\"\n",
    "        if not self.texture_maps:\n",
    "            return None\n",
    "        h_frame, w_frame = frame.shape[:2]\n",
    "\n",
    "        # Definir Zona de Búsqueda\n",
    "        if full_scan:\n",
    "            sx1, sy1 = 0, 0\n",
    "            search_area = frame\n",
    "        else:\n",
    "            sw = self.search_window\n",
    "            if self.search_expansion:\n",
    "                sw = int(sw * 1.5)\n",
    "            sx1 = max(0, pred_x - sw)\n",
    "            sy1 = max(0, pred_y - sw)\n",
    "            sx2 = min(w_frame, pred_x + sw)\n",
    "            sy2 = min(h_frame, pred_y + sw)\n",
    "            search_area = frame[sy1:sy2, sx1:sx2]\n",
    "\n",
    "        if search_area.size == 0:\n",
    "            return None\n",
    "\n",
    "        best_score = -1\n",
    "        best_rect = None\n",
    "\n",
    "        # En Full Scan reducimos escalas para rendimiento; en local probamos zoom\n",
    "        scales = [1.0, 0.9, 0.8, 0.7, 0.6, 0.5] if not full_scan else [1.0]\n",
    "\n",
    "        for i, texture_map in enumerate(self.texture_maps):\n",
    "            target_color = self.target_colors_hsv[i]\n",
    "            for scale in scales:\n",
    "                # Redimensionado del Template (Zoom)\n",
    "                if scale != 1.0:\n",
    "                    t_w = int(texture_map.shape[1] * scale)\n",
    "                    t_h = int(texture_map.shape[0] * scale)\n",
    "                    if t_w < 10 or t_h < 10:\n",
    "                        continue\n",
    "                    try:\n",
    "                        curr_template = cv2.resize(texture_map, (t_w, t_h))\n",
    "                    except Exception:\n",
    "                        continue\n",
    "                else:\n",
    "                    curr_template = texture_map\n",
    "\n",
    "                # Chequeo de límites\n",
    "                if (curr_template.shape[0] >= search_area.shape[0] or\n",
    "                    curr_template.shape[1] >= search_area.shape[1]):\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    # Encaje\n",
    "                    res = cv2.matchTemplate(search_area, curr_template, cv2.TM_CCOEFF_NORMED)\n",
    "                    _, max_v, _, max_loc = cv2.minMaxLoc(res)\n",
    "\n",
    "                    # Filtro preliminar\n",
    "                    if max_v < self.texture_match_threshold:\n",
    "                        continue\n",
    "\n",
    "                    lx, ly = max_loc\n",
    "                    cand_w, cand_h = curr_template.shape[1], curr_template.shape[0]\n",
    "                    candidate_roi = search_area[ly:ly+cand_h, lx:lx+cand_w]\n",
    "\n",
    "                    final_score = max_v\n",
    "                    if candidate_roi.size > 0:\n",
    "                        # Filtros de color\n",
    "                        cand_hsv = cv2.cvtColor(candidate_roi, cv2.COLOR_BGR2HSV)\n",
    "                        cand_avg = np.mean(cand_hsv, axis=(0, 1))\n",
    "                        diff_h = abs(cand_avg[0] - target_color[0])\n",
    "                        if diff_h > 90:\n",
    "                            diff_h = 180 - diff_h\n",
    "\n",
    "                        # Si varía más de 15 grados, es otro color -> DESCARTAR\n",
    "                        if diff_h > 15:\n",
    "                            continue\n",
    "                        # Veto de Saturación (Anti-Sombras/Grises)\n",
    "                        if cand_avg[1] < 60:\n",
    "                            continue\n",
    "\n",
    "                        diff_s = abs(cand_avg[1] - target_color[1])\n",
    "                        penalty = (diff_h * 0.005) + (diff_s * 0.002)\n",
    "                        final_score = max_v - penalty\n",
    "\n",
    "                    # Umbral Final\n",
    "                    # Si estamos perdidos, exigimos 80% de seguridad.\n",
    "                    # Si estamos trackeando, exigimos 65%.\n",
    "                    required_score = 0.80 if full_scan else self.texture_match_threshold\n",
    "                    if final_score > required_score and final_score > best_score:\n",
    "                        best_score = final_score\n",
    "                        global_x = sx1 + lx\n",
    "                        global_y = sy1 + ly\n",
    "                        cx_new = global_x + cand_w // 2\n",
    "                        cy_new = global_y + cand_h // 2\n",
    "                        best_rect = (cx_new, cy_new, cand_w, cand_h)\n",
    "\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "        # Filtro de Distancia Euclidiana\n",
    "        # Si el Kalman dice que está en X, y encontramos algo muy lejos, lo descartamos.\n",
    "        if best_rect and not full_scan:\n",
    "            bx, by = best_rect[0], best_rect[1]\n",
    "            dist = np.sqrt((bx - pred_x)**2 + (by - pred_y)**2)\n",
    "            max_dist = 150 if self.search_expansion else 100\n",
    "            if dist > max_dist:\n",
    "                return None\n",
    "\n",
    "        return best_rect\n",
    "\n",
    "    def detect_object(self, frame):\n",
    "        \"\"\"\n",
    "        Orquestador de la detección del objeto a seguir.\n",
    "\n",
    "        Estrategia Escalonada:\n",
    "        - Intenta tracking rápido (CSRT).\n",
    "        - Si falla, usa Kalman para predecir.\n",
    "        - Intenta recuperación por textura buscando en el área predicha por el filtro de Kalman.\n",
    "        - Si lleva > 30 frames perdido, intenta recuperación por textura denominado modo pánico.\n",
    "        \"\"\"\n",
    "        if self.calibration_stage < 3:\n",
    "            return None, None\n",
    "\n",
    "        success, bbox = self.tracker.update(frame)\n",
    "        if success:\n",
    "            # Tracking CSRT Exitoso\n",
    "            x, y, w, h = [int(v) for v in bbox]\n",
    "            cx, cy = x + w // 2, y + h // 2\n",
    "            self.kalman.correct(np.array([[np.float32(cx)], [np.float32(cy)]]))\n",
    "            self.roi = (x, y, w, h)\n",
    "            self.lost_frames = 0\n",
    "            self.search_expansion = False\n",
    "            self.camera_tracking_to_mouse_input(cx, cy, frame.shape)\n",
    "\n",
    "            mask = np.zeros(frame.shape[:2], dtype=np.uint8)\n",
    "            cv2.rectangle(mask, (x, y), (x+w, y+h), 255, -1)\n",
    "            return (cx, cy), mask\n",
    "\n",
    "        # Tracking Fallido -> Usar Predicción + Recuperación\n",
    "        prediction = self.kalman.predict()\n",
    "        pred_cx, pred_cy = int(prediction[0]), int(prediction[1])\n",
    "\n",
    "        self.lost_frames += 1\n",
    "        force_full_scan = self.lost_frames > 30 # Activar escaneo global si llevamos tiempo perdidos\n",
    "\n",
    "        result = self.detect_by_texture(frame, pred_cx, pred_cy, full_scan=force_full_scan)\n",
    "        if result:\n",
    "            # Si recupera algo\n",
    "            cx, cy, w_new, h_new = result\n",
    "            self.kalman.correct(np.array([[np.float32(cx)], [np.float32(cy)]]))\n",
    "            # Resetear Kalman para la nueva posición\n",
    "            self.kalman.statePost = np.array([[np.float32(cx)], [np.float32(cy)], [0], [0]], np.float32)\n",
    "\n",
    "            x_roi = int(cx - w_new/2)\n",
    "            y_roi = int(cy - h_new/2)\n",
    "            self.roi = (x_roi, y_roi, w_new, h_new)\n",
    "\n",
    "            self.tracker = cv2.TrackerCSRT_create()\n",
    "            self.tracker.init(frame, self.roi)\n",
    "            self.lost_frames = 0\n",
    "            self.search_expansion = False\n",
    "            self.camera_tracking_to_mouse_input(cx, cy, frame.shape)\n",
    "            return (cx, cy), None\n",
    "\n",
    "        self.search_expansion = True\n",
    "        if force_full_scan:\n",
    "            return (None, None)\n",
    "        return ((pred_cx, pred_cy), None) if self.lost_frames < 20 else (None, None)\n",
    "\n",
    "    def init_kalman(self, x, y):\n",
    "        \"\"\"\n",
    "        Configura el Filtro de Kalman.\n",
    "        Modelo de velocidad constante (posición x,y y velocidad vx, vy).\n",
    "        Ajustado para movimientos rápidos de ratón (baja inercia).\n",
    "        \"\"\"\n",
    "        self.kalman = cv2.KalmanFilter(4, 2)\n",
    "        self.kalman.measurementMatrix = np.array([[1,0,0,0], [0,1,0,0]], np.float32)\n",
    "        self.kalman.transitionMatrix = np.array([[1,0,1,0], [0,1,0,1], [0,0,1,0], [0,0,0,1]], np.float32)\n",
    "        self.kalman.processNoiseCov = np.eye(4, dtype=np.float32) * 1.0\n",
    "        self.kalman.statePost = np.array([[np.float32(x)], [np.float32(y)], [0], [0]], np.float32)\n",
    "        self.kalman.statePre = self.kalman.statePost.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc95cfa8",
   "metadata": {},
   "source": [
    "## Módulo De ejecución principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9733e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Si lo pones True, el movimiento SOLO se enviará si detecta CS2 en primer plano.\n",
    "RESTRICT_MOVEMENT_TO_CS2 = False\n",
    "\n",
    "def _stage_color(stage: int):\n",
    "    if stage == 0:\n",
    "        return (0, 255, 255)   # amarillo\n",
    "    if stage == 1:\n",
    "        return (255, 100, 0)   # naranja\n",
    "    if stage == 2:\n",
    "        return (0, 100, 255)   # azul\n",
    "    return (0, 255, 0)\n",
    "\n",
    "def _draw_click_points(display, tracker: ObjectTracker):\n",
    "    \"\"\"\n",
    "    Puntos GRANDES y visibles donde pinchas:\n",
    "    - Historial (hasta 9 clicks) con color por fase y número 1..3.\n",
    "    - Puntos actuales de la fase con contorno blanco.\n",
    "    \"\"\"\n",
    "    for idx, (px, py) in enumerate(tracker.all_clicks_history):\n",
    "        stage = min(idx // 3, 2)\n",
    "        num = (idx % 3) + 1\n",
    "        col = _stage_color(stage)\n",
    "        cv2.circle(display, (px, py), 4, (0, 0, 0), 2)\n",
    "        cv2.putText(display, str(num), (px + 10, py - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, col, 2)\n",
    "\n",
    "    if tracker.calibration_stage < 3:\n",
    "        col = _stage_color(tracker.calibration_stage)\n",
    "        for i, (px, py) in enumerate(tracker.current_clicks_coords):\n",
    "            cv2.circle(display, (px, py), 4, (255, 255, 255), 2)\n",
    "            cv2.putText(display, str(i + 1), (px + 12, py + 14),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "\n",
    "def main():\n",
    "    global RESTRICT_MOVEMENT_TO_CS2\n",
    "    WIN = \"CS2-Control (Pose + Tracker)\"\n",
    "    cv2.namedWindow(WIN, cv2.WINDOW_NORMAL)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(\"No pude abrir la cámara (VideoCapture(0)).\")\n",
    "\n",
    "    pose_ctrl = PoseMovementController()\n",
    "    kb_mgr = KeyboardMoveManager()\n",
    "    tracker = ObjectTracker()\n",
    "\n",
    "    movement_control_enabled = False\n",
    "    frame_count = 0\n",
    "\n",
    "    def on_mouse(event, x, y, flags, param):\n",
    "        tracker.mouse_callback(event, x, y, flags, param)\n",
    "    cv2.setMouseCallback(WIN, on_mouse)\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            ok, frame = cap.read()\n",
    "            if not ok:\n",
    "                break\n",
    "\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            display = frame.copy()\n",
    "            h, w = display.shape[:2]\n",
    "\n",
    "            # Detectar Ventana Activa\n",
    "            frame_count += 1\n",
    "            if frame_count % 30 == 0:\n",
    "                title = tracker.get_active_window_title()\n",
    "                tracker.cs2_active = (tracker.COUNTER_STRIKE_WINDOW_NAME in title)\n",
    "\n",
    "\n",
    "            # LOGICA TRACKER (PISTOLA)\n",
    "\n",
    "            if tracker.calibration_stage < 3:\n",
    "                tracker.process_pending_click(frame)\n",
    "\n",
    "            shot = False\n",
    "            result_pos = (None, None)\n",
    "\n",
    "            if tracker.calibration_stage == 3:\n",
    "                shot = tracker.detect_shoot(frame)\n",
    "                result_pos, _mask = tracker.detect_object(frame)\n",
    "\n",
    "            # DIBUJAR TRACKER HUD\n",
    "            cv2.line(display, (w // 2, 0), (w // 2, h), (0, 255, 255), 1)\n",
    "            cv2.line(display, (0, h // 2), (w, h // 2), (0, 255, 255), 1)\n",
    "\n",
    "            if tracker.calibration_stage == 0:\n",
    "                txt, col = f\"1. CALIBRA PISTOLA: DERECHA ({len(tracker.current_clicks_coords)}/3)\", _stage_color(0)\n",
    "            elif tracker.calibration_stage == 1:\n",
    "                txt, col = f\"2. CALIBRA PISTOLA: IZQUIERDA ({len(tracker.current_clicks_coords)}/3)\", _stage_color(1)\n",
    "            elif tracker.calibration_stage == 2:\n",
    "                txt, col = f\"3. CALIBRA PISTOLA: CENTRO ({len(tracker.current_clicks_coords)}/3)\", _stage_color(2)\n",
    "            else:\n",
    "                if tracker.camera_control_enabled and tracker.cs2_active:\n",
    "                    txt = \"JUEGO ACTIVO: PISTOLA + MOV\"\n",
    "                    col = (0, 255, 0)\n",
    "                else:\n",
    "                    txt, col = \"PISTOLA OK. (Pulsa C para activar raton)\", (0, 255, 0)\n",
    "\n",
    "            cv2.putText(display, txt, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, col, 2)\n",
    "\n",
    "            # Puntos visibles donde pinchas\n",
    "            _draw_click_points(display, tracker)\n",
    "\n",
    "            # DIBUJAR ROI TRACKER\n",
    "            if tracker.calibration_stage == 3 and tracker.roi and tracker.show_roi:\n",
    "                rx, ry, rw, rh = tracker.roi\n",
    "                col_roi = (0,0,255) if tracker.lost_frames > tracker.max_lost_frames else (0,255,0)\n",
    "                cv2.rectangle(display, (rx, ry), (rx+rw, ry+rh), col_roi, 2)\n",
    "\n",
    "            if result_pos and result_pos[0] is not None:\n",
    "                cx, cy = result_pos\n",
    "                cv2.circle(display, (cx, cy), 8, (0, 255, 255), -1)\n",
    "\n",
    "\n",
    "            # 2. LOGICA POSE (CUERPO) -> GATED por Tracker\n",
    "\n",
    "            pose_stage_display = \"ESPERANDO PISTOLA...\"\n",
    "            hold = MoveHold.NEUTRAL\n",
    "            do_jump = False\n",
    "\n",
    "            if tracker.calibration_stage >= 3:\n",
    "                hold, do_jump, stage, _ = pose_ctrl.process_frame(display)\n",
    "\n",
    "                if stage == \"WAIT\":\n",
    "                    pose_stage_display = \"4. POSE: ENTRA EN CAMARA...\"\n",
    "                elif stage == \"NEUTRAL\":\n",
    "                    pose_stage_display = \"5. POSE: QUIETO (NEUTRAL)...\"\n",
    "                elif stage == \"FORWARD\":\n",
    "                    pose_stage_display = \"6. POSE: INCLINATE (FORWARD)...\"\n",
    "                elif stage == \"DONE\":\n",
    "                    pose_stage_display = f\"ACCION: {hold.name}\" + (\"+JUMP\" if do_jump else \"\")\n",
    "\n",
    "                    if not movement_control_enabled:\n",
    "                        movement_control_enabled = True\n",
    "                        print(\">> MOVIMIENTO ACTIVADO AUTOMATICAMENTE <<\")\n",
    "\n",
    "            cv2.putText(display, pose_stage_display, (10, 60),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "\n",
    "            # 3. APLICAR INPUTS (MOVIMIENTO)\n",
    "\n",
    "            allow_movement = (\n",
    "                movement_control_enabled and\n",
    "                tracker.calibration_stage >= 3 and\n",
    "                pose_ctrl.stage == \"DONE\" and\n",
    "                (not RESTRICT_MOVEMENT_TO_CS2 or tracker.cs2_active)\n",
    "            )\n",
    "\n",
    "            if allow_movement:\n",
    "                kb_mgr.set_hold(hold)\n",
    "                if do_jump:\n",
    "                    kb_mgr.jump()\n",
    "            else:\n",
    "                kb_mgr.set_hold(MoveHold.NEUTRAL)\n",
    "\n",
    "\n",
    "            # 4. INFO GENERAL + SENS\n",
    "\n",
    "            st = (\n",
    "                f\"RATON={'ON' if tracker.camera_control_enabled else 'OFF'} \"\n",
    "                f\"TECLAS={'ON' if movement_control_enabled else 'OFF'} \"\n",
    "                f\"CS2={'SI' if tracker.cs2_active else 'NO'} \"\n",
    "                f\"SENS={tracker.sensitivity:.2f}\"\n",
    "            )\n",
    "            cv2.putText(display, st, (10, h - 55),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.55, (0,255,0), 2)\n",
    "\n",
    "            cv2.putText(display, \"Raton: [C] Teclas [M] Mov [R] Reset Tracker [P] Reset Pose [+/-] Sens\",\n",
    "                        (10, h - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200,200,200), 1)\n",
    "\n",
    "            cv2.imshow(WIN, display)\n",
    "\n",
    "            # TECLAS CONTROL PROGRAMA\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key in (ord('q'), ord('Q'), 27):\n",
    "                break\n",
    "            elif key in (ord('c'), ord('C')):\n",
    "                tracker.camera_control_enabled = not tracker.camera_control_enabled\n",
    "            elif key in (ord('m'), ord('M')):\n",
    "                movement_control_enabled = not movement_control_enabled\n",
    "                if not movement_control_enabled:\n",
    "                    kb_mgr.set_hold(MoveHold.NEUTRAL)\n",
    "            elif key in (ord('r'), ord('R')):\n",
    "                tracker.reset_state()\n",
    "                kb_mgr.set_hold(MoveHold.NEUTRAL)\n",
    "            elif key in (ord('p'), ord('P')):\n",
    "                pose_ctrl.reset()\n",
    "                movement_control_enabled = False\n",
    "                kb_mgr.set_hold(MoveHold.NEUTRAL)\n",
    "                print(\">> POSE RESETEADA: vuelve a calibrar (Neutral -> Forward) <<\")\n",
    "\n",
    "            # + / - para sensibilidad del raton \n",
    "            elif key in (ord('+'), ord('=')):  # '=' por si el teclado manda '=' al pulsar '+'\n",
    "                tracker.adjust_mouse_sensitivity(+0.05)\n",
    "                print(f\">> SENS={tracker.sensitivity:.2f} <<\")\n",
    "            elif key in (ord('-'), ord('_')):  # '_' por si viene con shift\n",
    "                tracker.adjust_mouse_sensitivity(-0.05)\n",
    "                print(f\">> SENS={tracker.sensitivity:.2f} <<\")\n",
    "\n",
    "    finally:\n",
    "        kb_mgr.release_all()\n",
    "        pose_ctrl.close()\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_PROJECT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
